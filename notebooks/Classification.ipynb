{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nfrom sklearn import datasets, ensemble, model_selection\nimport matplotlib.pyplot as plt\nimport pandas_profiling as pp\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=datasets.load_breast_cancer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.DESCR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.feature_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y=data.data,data.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(data=data.data,columns=data.feature_names)\ndf['Target']=y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pp.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=list(df.columns[:5])\nsns.pairplot(df[cols])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,hue='Target',vars=df.columns[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtr,xval,ytr,yval=model_selection.train_test_split(x,y,test_size=.3,random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ens.RandomForestClassifier(n_estimators=10,oob_score=True,random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtr,ytr)\nmodel.score(xtr,ytr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(xval,yval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(xval)\nconfusion_matrix(yval,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n#     classes = classes[unique_labels(y_true, y_pred)]\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(yval,pred,['Malignant','Benign'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.oob_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What would happen if we increase the number of trees?"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel=ensemble.RandomForestClassifier(n_estimators=30,oob_score=True,random_state=25)\nmodel.fit(xtr,ytr)\nmodel.score(xtr,ytr),model.oob_score_,model.score(xval,yval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What would happen if we set a value for max_features? By default it is set to 'auto' which uses square root of total number of features."},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ensemble.RandomForestClassifier(n_estimators=10,max_features=5,oob_score=True,random_state=25)\nmodel.fit(xtr,ytr)\nmodel.score(xtr,ytr),model.oob_score_,model.score(xval,yval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's change other parameters in the model. This time we set max_depth to 3. If this value is not set the tree grows until it reaches the minimum number of data points (min_sample_split) in every leaf."},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ensemble.RandomForestClassifier(n_estimators=10,max_depth=3,oob_score=True,random_state=25)\nmodel.fit(xtr,ytr)\nmodel.score(xtr,ytr),model.oob_score_,model.score(xval,yval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if we use max_depth of 3 and more trees?"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ensemble.RandomForestClassifier(n_estimators=50,max_depth=3,oob_score=True,random_state=25)\nmodel.fit(xtr,ytr)\nmodel.score(xtr,ytr),model.oob_score_,model.score(xval,yval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Optimization\nAs you can see performance of the model relies on the values of the model parameters. How do we know what values we should choose? These parameters that define the model are called hyperparameter. To find the best values we need to perform hyperparameter optimization. There are various methods for hyperparameter optimization. What we are using here is called grid search. Basically, we choose a few values for some of the parameters and try every combination. Obviously, this method is not practicall if we have many hyperparameters and a wide range of values for each. "},{"metadata":{"trusted":true},"cell_type":"code","source":"params={'max_features':[4,5,6,7],'max_depth':[2,3,4,5],'n_estimators':[20,50,100]}\ngrid_search=model_selection.GridSearchCV(estimator=ensemble.RandomForestClassifier(random_state=21,oob_score=True),\n                                         param_grid=params,\n                                         cv=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we created a dictionary containing the parameters we want to set and the values we want to try. We passed the model we want to train, as well as the parameter values we want to try and cv! What is cv? Cross Validation.\nCross Validation split the data into n folds. Then, the model is trained using n-1 folds and then tested (validated) on the fold that we haven't used. We can do this n times (one for each fold) and take the average of the validation score. This is a useful method to make sure that a good score wasn't just by chance. \nWe are using cv=5 here which means we are splitting the data into 5 sets.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# depends on the number of trials this might take some time to run.\ngrid_search.fit(xtr,ytr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=grid_search.best_estimator_\nmodel.score(xtr,ytr),model.oob_score_,model.score(xval,yval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(data.feature_names,model.feature_importances_);\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We managed to slightly improve the model. Is there room for more improvement? Certainly. We could do some feature engineering, which sometimes significantly improve the model. As we saw in the plots some of the features highly correlate. That means all the information we need, we can get from one of them. Having both of them in the dataset is unnecessary and most of the time even lowers the model accuracy. Also, Sometimes removing features that have low importance (according to the plot above) can also improve the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}